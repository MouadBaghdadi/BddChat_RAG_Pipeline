# BddChat

BddChat is a Python application that allows users to interact with a question-answering model based on contextual information. It provides a simple graphical interface for users to input queries and receive responses generated by the model.

## Installation

To install BddChat, follow these steps:

### Clone the repository to your local machine:

```bash
git clone https://github.com/MouadBaghdadi/BddChat_RAG_Pipeline.git
```
### Navigate to the project directory:
```bash
cd BddChat
```
### Install the required dependencies:
```bash
pip install -r requirements.txt
```
### Usage
To use BddChat, run the main.py file:

```bash
python main.py
```
This will launch the graphical interface where you can input your queries and receive responses.

### How it Works
BddChat utilizes a Retrieval-Augmented Generation (RAG) pipeline to generate responses to user queries. Here's how it works:

PDF Ingestion: The pipeline ingests a PDF document containing relevant information. In this example, we use a scholarly database textbook as the source of information.
Semantic Search: When a user submits a query, the pipeline first performs a semantic search to identify relevant passages of text from the PDF document. It uses a pre-trained SentenceTransformer model to encode the query and passages into embedding vectors and computes their cosine similarity.
Context Augmentation: The pipeline augments the user's query with the context of the identified passages. This ensures that the response generated by the model is informed by the relevant information from the PDF document.
Language Model Generation: Finally, the pipeline uses a pre-trained language model (in this case, Google's GEMMA-2B-IT) to generate a response to the augmented query.
Display Response: The generated response is displayed to the user in the graphical interface, allowing for seamless interaction with the RAG pipeline.
Example
Here's an example of how to use BddChat:

Launch the application by running main.py.
In the graphical interface, enter your query in the input field.
Click the "questionne" button to submit your query.
The application will display the response generated by the model in the text box below.
Customization
You can customize the behavior of BddChat by modifying the main.py file. This file contains the logic for initializing the application, including setting up the graphical interface and handling user interactions.

### An exemple of the difference between the LLM's response to an augmented prompt and non augmented one:
* Without aumentation:

<img width="741" alt="without augmentation" src="https://github.com/MouadBaghdadi/RAG_Project/assets/101417636/55ea3cd4-5ae8-4d6e-9dc0-df168d9a3248">

* with augmentation:

<img width="733" alt="with augmentation" src="https://github.com/MouadBaghdadi/RAG_Project/assets/101417636/be08815f-533f-496e-806c-4fa59e4db54a">

### Contributing
If you'd like to contribute to BddChat, feel free to fork the repository and submit a pull request. We welcome contributions of all kinds, including bug fixes, feature enhancements, and documentation improvements.



