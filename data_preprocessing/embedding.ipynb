{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.40.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", device= \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>tokens_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1  Préambule  Après onze années en tant que ch...</td>\n",
       "      <td>94.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>J’ai alors fait des diapos pour chaque chapitr...</td>\n",
       "      <td>46.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2  Pour finir, je pense avoir synthétisé ma mo...</td>\n",
       "      <td>12.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>13  Présentation du cours  Ce cours s’adresse ...</td>\n",
       "      <td>77.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>Théorie des ensembles,  3. Logique du premier ...</td>\n",
       "      <td>19.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>145</td>\n",
       "      <td>145  Annexe 1 : Les Fonctions dans SQL  92  Do...</td>\n",
       "      <td>69.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>146</td>\n",
       "      <td>146  IS [NOT] NULL  NULL  INNER JOIN  Jointure...</td>\n",
       "      <td>28.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>147</td>\n",
       "      <td>147  Annexe 2 : Outils Pédagogiques  1. Functi...</td>\n",
       "      <td>45.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>147</td>\n",
       "      <td>Il est utilisé par les étudiants pour confront...</td>\n",
       "      <td>12.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>148</td>\n",
       "      <td>148  2. Free Relational Algebra Interpreter  F...</td>\n",
       "      <td>47.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     page_number                                     sentence_chunk  \\\n",
       "0              1  1  Préambule  Après onze années en tant que ch...   \n",
       "1              1  J’ai alors fait des diapos pour chaque chapitr...   \n",
       "2              2  2  Pour finir, je pense avoir synthétisé ma mo...   \n",
       "3             13  13  Présentation du cours  Ce cours s’adresse ...   \n",
       "4             13  Théorie des ensembles,  3. Logique du premier ...   \n",
       "..           ...                                                ...   \n",
       "160          145  145  Annexe 1 : Les Fonctions dans SQL  92  Do...   \n",
       "161          146  146  IS [NOT] NULL  NULL  INNER JOIN  Jointure...   \n",
       "162          147  147  Annexe 2 : Outils Pédagogiques  1. Functi...   \n",
       "163          147  Il est utilisé par les étudiants pour confront...   \n",
       "164          148  148  2. Free Relational Algebra Interpreter  F...   \n",
       "\n",
       "     tokens_number  \n",
       "0            94.00  \n",
       "1            46.75  \n",
       "2            12.75  \n",
       "3            77.50  \n",
       "4            19.50  \n",
       "..             ...  \n",
       "160          69.25  \n",
       "161          28.50  \n",
       "162          45.25  \n",
       "163          12.75  \n",
       "164          47.75  \n",
       "\n",
       "[165 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('bdd.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_chunk = [item for item in data['sentence_chunk']]\n",
    "len(list_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 7s\n",
      "Wall time: 1min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0084, -0.0511, -0.0165,  ...,  0.0472, -0.0016, -0.0583],\n",
       "        [-0.0048, -0.0710, -0.0338,  ...,  0.0559, -0.0208, -0.0427],\n",
       "        [ 0.0315,  0.0174, -0.0177,  ...,  0.0601,  0.0472, -0.0627],\n",
       "        ...,\n",
       "        [-0.0117,  0.0014, -0.0473,  ..., -0.0003, -0.0136, -0.0288],\n",
       "        [-0.0045, -0.0186, -0.0273,  ...,  0.0312, -0.0201, -0.0280],\n",
       "        [-0.0380, -0.0087, -0.0266,  ...,  0.0166, -0.0234, -0.0320]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#embed all texts in batchs of 32 \n",
    "text_chunk_embeddings = embedding_model.encode(sentences=list_chunk,\n",
    "                                               batch_size = 32,\n",
    "                                               convert_to_tensor=True )\n",
    "text_chunk_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([165, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunk_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the embeddings \n",
    "embedding_values = text_chunk_embeddings.tolist()\n",
    "data['embeddings'] = embedding_values\n",
    "data.head()\n",
    "\n",
    "data.to_csv(\"bdd.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
